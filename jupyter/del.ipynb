{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG system\n",
    "* LLM: GPT 3.0 turbo/Gemini\n",
    "* Langchain\n",
    "* Vector DB: ChromaDB\n",
    "* Embedding: \n",
    "  * \n",
    "  * GanymedeNil/text2vec-large-chinese\n",
    "    1. Use a pipeline as a high-level helper\n",
    "      * 快速、自動話處理\n",
    "    2. Load model directly\n",
    "      * 彈性較大、易優化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chat_models import GoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料處理與資後庫匯入\n",
    "* Data: 綠色金融行動方案3.pdf\n",
    "* Document Loaders:\n",
    "  * Langchain offers around 55 types of document loaders, including loaders for Word, CSV, PDF, GoogleDrive, and YouTube\n",
    "* Split Documents: \n",
    "  * Text splitter splits documents or text into chunks to avoid exceeding the LLM's token limit\n",
    "  * The main parameters include chunk_size (determining the max number of characters per chunk) and chunk_overlap (specifying the overlapping characters between consecutive chunks)\n",
    "* Embedding Model: \n",
    "  * to convert the chunks of text into vectors. \n",
    "  * LangChain provides interfaces for many Embedding models.\n",
    "  * [open source Embedding Model comparison](https://ithelp.ithome.com.tw/articles/10298540?sc=rss.iron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "loader = PyMuPDFLoader(\"綠色金融行動方案3.pdf\")\n",
    "PDF_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=5)\n",
    "all_splits = text_splitter.split_documents(PDF_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show text\n",
    "print(len(all_splits))\n",
    "print(all_splits[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "model_name = \"aspire/acge_text_embedding\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                  multi_process=True,\n",
    "                                  model_kwargs=model_kwargs,\n",
    "                                  encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 結果匯入 VectorDB\n",
    "persist_directory = 'db'\n",
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 啟用 LLM 服務: By Google AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCgEarkxRl7XzCxeoTG3wXhIVSFtw4Ud7g\"\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "Google_llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Retrieval + Query LLM\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa_Google = RetrievalQA.from_chain_type(\n",
    "    llm=Google_llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RAG\n",
    "query = \"綠色金融行動方案 3.0 是什麼？\"\n",
    "qa_Google.run(query)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
